{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMXbooWe2xWYj2roGLaaGe7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amfei/Causal_Inference/blob/main/Causal_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Causal inference** is the process of determining whether one variable (often called the \"treatment\" or \"cause\") **directly affects another variable** (the \"outcome\" or \"effect\"). This is different from **correlation**, which simply measures whether two variables **move together**, without implying that one causes the other.\n",
        "\n",
        "Example: The Effect of Studying on Exam Scores\n",
        "Imagine you're a student trying to figure out if studying more hours leads to better exam scores. Here's how you might approach this question using causal inference:\n",
        "\n",
        "Treatment (Cause): Number of hours spent studying.\n",
        "Outcome (Effect): Exam score.\n",
        "Confounders: Other variables that might affect both studying and exam scores (e.g., previous knowledge, hours of sleep, access to study materials).\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "APzzGuyzDBHa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# There are various methods for causal inference, including **randomized controlled trials (RCTs)**, **instrumental variables (IV), propensity score matching**, and more recently, methods using g**raphical models and machine learning.**\n",
        "\n",
        "## I'll demonstrate a simple example of causal inference using the DoWhy library, which is designed for causal analysis. DoWhy provides a straightforward way to specify causal models and perform causal inference."
      ],
      "metadata": {
        "id": "oUFaSFbjFfe7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## **Propensity Score:** The probability of a unit (e.g., a customer) receiving the treatment given their observed characteristics.\n",
        "\n",
        "## Problem: **Estimating the Effect of a** Loyalty Program **on** Insurance Claims\n",
        "### Suppose an insurance company wants to estimate the effect of enrolling customers in a loyalty program on the number of insurance claims they file. Since customers are not randomly assigned to the loyalty program, there may be **confounding variables** that influence both the enrollment and the outcome (e.g., age, income, past claims history).\n",
        "\n",
        "Steps for Propensity Score Application\n",
        "\n",
        "**1. Data Preparation:** Create a dataset with treatment, outcome, and covariates.\n",
        "\n",
        "**2. Propensity Score Estimation:** Estimate the probability of treatment assignment based on observed covariates.\n",
        "\n",
        "**3. Matching/Weighting/Stratification:** Use propensity scores to balance the treatment and control groups.\n",
        "\n",
        "**4. Outcome Analysis:** Compare the outcomes between the balanced groups to estimate the treatment effect.\n",
        "\n"
      ],
      "metadata": {
        "id": "av8ksMsDGCE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Generate synthetic data\n",
        "num_samples = 1000\n",
        "data = {\n",
        "    'age': np.random.randint(18, 70, size=num_samples),\n",
        "    'income': np.random.normal(50000, 10000, size=num_samples),\n",
        "    'past_claims': np.random.randint(0, 5, size=num_samples),\n",
        "    'loyalty_program': np.random.binomial(1, 0.3, size=num_samples),  # 30% in loyalty program\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Introduce a causal relationship\n",
        "df['num_claims'] = df['loyalty_program'] * -0.5 + df['past_claims'] * 0.3 + np.random.normal(0, 1, num_samples)\n",
        "df['num_claims'] = df['num_claims'].apply(lambda x: max(x, 0))  # Ensure non-negative claims\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "my-844AEER8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Propensity Score Estimation**\n",
        "Estimate the propensity scores using logistic regression:\n"
      ],
      "metadata": {
        "id": "NkmSWABIEvRL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Define features and treatment\n",
        "X = df[['age', 'income', 'past_claims']]\n",
        "y = df['loyalty_program']\n",
        "\n",
        "# Fit logistic regression to estimate propensity scores\n",
        "logistic = LogisticRegression()\n",
        "logistic.fit(X, y)\n",
        "\n",
        "# Predict propensity scores\n",
        "df['propensity_score'] = logistic.predict_proba(X)[:, 1]\n",
        "\n",
        "# Display the first few rows with propensity scores\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "RZF2_cBnER-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Matching:** Treated units (enrolled in the loyalty program) are matched with control units (not enrolled) based on their propensity scores using nearest neighbor matching.\n",
        "\n",
        "## Matching is a method to pair each treated unit with one or more control units that have similar propensity scores. This aims to balance the distribution of observed covariates between the treated and control groups, reducing the bias due to confounding variables.\n",
        "\n",
        "## Nearest Neighbor Matching: Each treated unit is matched with the closest control unit(s) based on the propensity score. In this example, we use 1-to-1 nearest neighbor matching.\n",
        "\n",
        "### In observational studies, like our insurance example, the treatment (enrollment in a loyalty program) is not randomly assigned. This can lead to biased estimates of the treatment effect because the treated and untreated groups might differ in ways that also affect the outcome (number of claims). Matching helps to make these groups comparable.\n",
        "\n",
        "### How do we do Matching?\n",
        "We use propensity scores, which are the estimated probabilities that a customer will be in the loyalty program based on their characteristics (age, income, past claims). We then match each treated customer with one or more control customers who have similar propensity scores.\n",
        "\n",
        "### Steps in Matching for our example:\n",
        "\n",
        "**Estimate Propensity Scores:** Use logistic regression to calculate the probability of each customer being in the loyalty program based on their age, income, and past claims.\n",
        "\n",
        "**Find Matches:** For each customer in the loyalty program (treated), find a customer not in the program (control) with a similar propensity score. This is like finding \"twins\" based on the probability of receiving the treatment.\n",
        "\n",
        "**Create Matched Dataset:** Combine the treated customers and their matched controls into a new dataset that will be used for analysis.\n",
        "\n"
      ],
      "metadata": {
        "id": "rXwt8UmVLFNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Separate treated and control groups\n",
        "treated = df[df['loyalty_program'] == 1]\n",
        "control = df[df['loyalty_program'] == 0]\n",
        "\n",
        "# Fit nearest neighbors model\n",
        "nn = NearestNeighbors(n_neighbors=1)\n",
        "nn.fit(control[['propensity_score']])\n",
        "\n",
        "# Find nearest neighbors in the control group for each treated unit\n",
        "distances, indices = nn.kneighbors(treated[['propensity_score']])\n",
        "\n",
        "# Get matched control units\n",
        "matched_controls = control.iloc[indices.flatten()]\n",
        "\n",
        "# Combine treated and matched control units\n",
        "matched_df = pd.concat([treated, matched_controls])\n",
        "\n",
        "# Display the first few rows of the matched dataset\n",
        "print(matched_df.head())\n"
      ],
      "metadata": {
        "id": "g3fRfsavESC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate average treatment effect\n",
        "ate = matched_df[matched_df['loyalty_program'] == 1]['num_claims'].mean() - \\\n",
        "      matched_df[matched_df['loyalty_program'] == 0]['num_claims'].mean()\n",
        "\n",
        "print(f'Average Treatment Effect (ATE): {ate}')\n"
      ],
      "metadata": {
        "id": "aTsCzVYoESEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## To solve the insurance loyalty claim problem using the **DoWhy** library, we can follow these steps:\n",
        "\n",
        "Data Preparation: Create synthetic data with baseline features and introduce a causal relationship.\n",
        "\n",
        "Causal Model Specification: Define the causal model including treatment, outcome, and confounders.\n",
        "\n",
        "Identify the Causal Effect: Use DoWhy to identify the causal effect.\n",
        "\n",
        "Estimate the Causal Effect: Estimate the causal effect using an appropriate method.\n",
        "\n",
        "Refute the Estimate: Perform robustness checks to ensure the validity of the causal effect"
      ],
      "metadata": {
        "id": "PXlsHMN7Wau3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dowhy\n",
        "from dowhy import CausalModel\n",
        "\n",
        "# Define the causal model\n",
        "model = CausalModel(\n",
        "    data=df,\n",
        "    treatment='loyalty_program',\n",
        "    outcome='num_claims',\n",
        "    common_causes=['age', 'income', 'past_claims']\n",
        ")\n",
        "\n",
        "# View the model\n",
        "model.view_model()\n"
      ],
      "metadata": {
        "id": "FF9mBqSyVcUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "identified_estimand = model.identify_effect()\n",
        "print(identified_estimand)\n"
      ],
      "metadata": {
        "id": "crq06kgsVkH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "estimate = model.estimate_effect(\n",
        "    identified_estimand,\n",
        "    method_name=\"backdoor.linear_regression\"\n",
        ")\n",
        "\n",
        "print(estimate)\n"
      ],
      "metadata": {
        "id": "nr-E4RmGESKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Refutation**: We perform robustness checks to ensure the causal effect is not due to random chance or unobserved confounders."
      ],
      "metadata": {
        "id": "kH_YeXbidbTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Refute the causal estimate\n",
        "refutation = model.refute_estimate(\n",
        "    identified_estimand,\n",
        "    estimate,\n",
        "    method_name=\"placebo_treatment_refuter\"\n",
        ")\n",
        "\n",
        "print(refutation)"
      ],
      "metadata": {
        "id": "ItYt25X2WCoB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}